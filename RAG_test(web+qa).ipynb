{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 📦 Install Required Packages\n",
        "# ---------------------------------------------\n",
        "!pip install -q chromadb sentence-transformers trafilatura requests groq nltk pandas"
      ],
      "metadata": {
        "id": "SIh4oSNFGekB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 📥 Import Libraries\n",
        "# ---------------------------------------------\n",
        "import requests\n",
        "import trafilatura\n",
        "import chromadb\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBxnk1nMIPIj",
        "outputId": "d9a11a4d-2d47-4cde-c3a2-68b832f1d344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 🧠 Setup ChromaDB and Embedder\n",
        "# ---------------------------------------------\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_store_combined\")\n",
        "web_collection = chroma_client.get_or_create_collection(\"web_context\")\n",
        "qa_collection = chroma_client.get_or_create_collection(\"qa_context\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2xg4Wu0IWgl",
        "outputId": "9f673560-da51-46cf-aeee-f69e60ec2b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 🧾 Step 1: Load your QA dataset and store as embeddings\n",
        "# ------------------------------------------------------------------------------\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "# Setup\n",
        "batch_size = 500\n",
        "qa_df = pd.read_csv(\"/content/questionsv4.csv\").dropna(subset=[\"questions\", \"answers\"])\n",
        "# Batching and insertion\n",
        "for i in tqdm(range(0, len(qa_df), batch_size)):\n",
        "    batch_df = qa_df.iloc[i:i+batch_size]\n",
        "\n",
        "    ids = [f\"qa_{j}\" for j in range(i, i + len(batch_df))]\n",
        "    documents = batch_df[\"answers\"].tolist()\n",
        "    queries = batch_df[\"questions\"].tolist()\n",
        "    embeddings = embedder.encode(queries, batch_size=64).tolist()\n",
        "    metadatas = [{\"original_query\": q} for q in queries]\n",
        "\n",
        "    qa_collection.add(\n",
        "        ids=ids,\n",
        "        documents=documents,\n",
        "        embeddings=embeddings,\n",
        "        metadatas=metadatas\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X26tIRdItO5",
        "outputId": "78c02bb5-c033-4fcf-eae4-ad29b606cd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 358/358 [28:32<00:00,  4.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 🚀 Step 2: Take user query input\n",
        "# ---------------------------------------------\n",
        "query = input(\"Enter your farming query: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_dFRyRhJHgL",
        "outputId": "1f357c6e-71b5-4416-f9da-b8960b927495"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your farming query: What pesticide should I use to control aphids in brinjal, and what is the dosage?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 🌐 Step 3: Get top URLs from n8n webhook\n",
        "# ---------------------------------------------\n",
        "n8n_webhook_url = \"https://rrajdev.app.n8n.cloud/webhook/farm-query\"\n",
        "response = requests.post(n8n_webhook_url, json={\"query\": query})\n",
        "\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(\"Raw Response:\", response.text)\n",
        "\n",
        "try:\n",
        "    urls = response.json().get(\"urls\", [])\n",
        "    print(f\"\\nTop {len(urls)} URLs Retrieved:\\n\", urls)\n",
        "except Exception as e:\n",
        "    print(\"Error parsing JSON:\", e)\n",
        "    urls = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqmzisnsQvVi",
        "outputId": "0425760b-f58a-4a38-cb45-c3a54f477cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Raw Response: {\"urls\":[\"https://www.youtube.com/watch?v=320D-41xt-M&pp=0gcJCfwAo7VqN5tD\",\"https://m.youtube.com/watch?v=BmLNAPT0gxw&t=345s\",\"https://www.youtube.com/watch?v=bqCBIP9TmcY\",\"https://kaybeebio.com/product/pesto-raze/\",\"https://labelsds.com/images/user_uploads/Malathion%20.50%20Label.pdf\"]}\n",
            "\n",
            "Top 5 URLs Retrieved:\n",
            " ['https://www.youtube.com/watch?v=320D-41xt-M&pp=0gcJCfwAo7VqN5tD', 'https://m.youtube.com/watch?v=BmLNAPT0gxw&t=345s', 'https://www.youtube.com/watch?v=bqCBIP9TmcY', 'https://kaybeebio.com/product/pesto-raze/', 'https://labelsds.com/images/user_uploads/Malathion%20.50%20Label.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 🧹 Step 4: Extract and store scraped content in ChromaDB\n",
        "# ---------------------------------------------------------------\n",
        "def fetch_and_extract(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=60, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        if response.status_code == 200:\n",
        "            return trafilatura.extract(response.text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "cleaned = []\n",
        "for url in urls:\n",
        "    content = fetch_and_extract(url)\n",
        "    if content:\n",
        "        cleaned.append({\"url\": url, \"content\": content})\n",
        "\n",
        "for i, entry in enumerate(cleaned):\n",
        "    embedding = embedder.encode(entry[\"content\"]).tolist()\n",
        "    web_collection.add(\n",
        "        ids=[f\"web_{i}_{query[:10]}\"],\n",
        "        documents=[entry[\"content\"]],\n",
        "        embeddings=[embedding],\n",
        "        metadatas=[{\"source\": entry[\"url\"]}]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQI6hdv8QyWw",
        "outputId": "a84ae4a8-3b16-4001-f9b2-3aedeca2a074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
            "ERROR:trafilatura.core:empty HTML tree: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zywrQS8vwqsK",
        "outputId": "744e7545-f89d-48cc-f8e0-551b9d1a6adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.youtube.com/watch?v=320D-41xt-M&pp=0gcJCfwAo7VqN5tD',\n",
              "  'content': 'About\\nPress\\nCopyright\\nContact us\\nCreators\\nAdvertise\\nDevelopers\\nTerms\\nPrivacy\\nPolicy & Safety\\nHow YouTube works\\nTest new features\\nNFL Sunday Ticket\\n© 2025 Google LLC'},\n",
              " {'url': 'https://m.youtube.com/watch?v=BmLNAPT0gxw&t=345s',\n",
              "  'content': 'About\\nPress\\nCopyright\\nContact us\\nCreators\\nAdvertise\\nDevelopers\\nTerms\\nPrivacy\\nPolicy & Safety\\nHow YouTube works\\nTest new features\\nNFL Sunday Ticket\\n© 2025 Google LLC'},\n",
              " {'url': 'https://www.youtube.com/watch?v=bqCBIP9TmcY',\n",
              "  'content': 'About\\nPress\\nCopyright\\nContact us\\nCreators\\nAdvertise\\nDevelopers\\nTerms\\nPrivacy\\nPolicy & Safety\\nHow YouTube works\\nTest new features\\nNFL Sunday Ticket\\n© 2025 Google LLC'},\n",
              " {'url': 'https://kaybeebio.com/product/pesto-raze/',\n",
              "  'content': 'Bio Pesticides Products Pesto Raze – Best Insecticide for Aphids, White Flies, Jassids and Hoppers | Plant Insect and Pest Control Product\\n₹322.00\\nIt is the best insecticide for aphids, white flies, and hoppers. Pesto Raze shows very high mortality against sucking pests infesting vegetable, fruit, flower, pulse, oilseed, food, and fodder crops. Pesto Raze is super effective against pests like brinjal white fly and tomato whitefly.\\nSKU: N/A\\nBest Organic Insecticide for Aphids, White Flies, All Sucking Pests etc.\\nPesto Raze is a bio insecticide, a phytoconstituents-based high-quality product manufactured from species of pharmaceutical eminence which is the best insecticide for aphids, white flies, hoppers, and all types of sucking pests. Pesto Raze shows very high mortality against sucking pests like aphids, jassids, and white flies infesting vegetable, flower, fruit, oilseed, pulse, food, and fodder crops. Pesto Raze is majorly effective in the control of aphids, white flies, brinjal white fly, chilli white, tomato whitefly, tomato aphid, paddy BPH, etc. As a botanical-based product, it triggers the phyto-tonic activities of plants and also activates the plant’s natural pest defence mechanism by producing secondary metabolites. This leads to a substantial improvement in crop productivity of a wide variety of crops also equips the plants with enhanced resilience against various stresses.\\nTo control the pest infestation to avoid any damage to the crop it is recommended to apply Pesto Raze at an interval of 7-8 days or it may be subjected to need-based use depending upon the intensity of the pest population on the crop.\\nUSP/Benefits\\nUSP/Benefits of the Pesto Raze (Best Organic Insecticide for Sucking Pests):\\n- Pesto Raze is known as bio pesticide product for plant-insect/pest control.\\n- It has the ability to control the white fly, aphids, and hoppers-infested to healthy plants.\\n- It is an organic insecticide effective in the control of cotton aphids, cotton white flies brinjal white fly, chilli whitefly, tomato whitefly, Tomato aphid, paddy BPH, etc.\\n- It also helps in improving the quality and yield of crops.\\n- Pesto Raze is an organic insecticide that is residue-free and suitable for organic farming.\\nProduct/Packaging availability:\\nPack Size available in 100ml, 250ml, 500ml, 1lit and 5ltr\\nUsage\\nMode of Action:\\nContact, Systemic, and Fumigant:\\nAntifeedent, Desiccation, Cytolysis activity and Knockout effect can be seen in neonates and early instars. Stomach poisoning, anti-molting hormonal changes, neurotoxicity, IGR activity for late instar, and multilevel target action lead to a bewildering detoxification system of the insect body which fails to survive & never develops resistance to this product.\\nPreventive:\\nPrevents sucking pest attack\\nCurative:\\nShows effective control in Aphids, Hoppers, and White flies of various spp.\\nPesto Raze (Insecticide for Sucking Pest): Spectrum of Action & Suggested Uses\\n| Crop |\\nPest |\\nMethod |\\nDosage-ml/ltr |\\n| Tomato |\\nAphid, Whitefly, Hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Chili |\\nAphid, Whitefly, Hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Brinjal |\\nAphid, Whitefly, Hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Potato |\\nAphid, Whitefly, Hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Cotton |\\nAphid, Whitefly, Hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Rice/Paddy |\\nBPH, Green leaf hopper |\\nSpraying |\\n1.5 – 2.5 |\\n| Mango |\\nHopper, Midge fly |\\nSpraying |\\n1.5 – 2.5 |\\n*Dose depending upon crop stage and initial pest population.\\nRecommended crops:\\nPesto Raze is recommended for all types of Fruits, Vegetables, Flowers, Oilseeds, Cereals-Pulses, Bulbs and Tubers, Spices, Herbal plants, Cash crops like Cotton, Sugarcane, and other Agriculture and Horticultural crops.\\nSpraying timing:\\nThe best time for spraying Pesto Raze is morning and evening. Avoid spraying during noon time when the temperature is high.\\nCompatibility:\\nIt is non-compatible with sulphur, copper base fungicides, and Bordeaux mixture.\\nFAQs\\nQ1 Which sucking insects does Pesto Raze control?\\nAns. Pesto Raze effectively controls various sucking pests of plants, such as whiteflies, aphids, and jassids, among others. Pesto Raze stands out as the ideal pest control solution for comprehensive sucking pest management in crops.\\nQ2 How can you manage whitefly infestations in tomatoes and chilli plants?\\nAns. If you’re facing issues with whiteflies in your tomato and chilli plants, turn to our Pesto Raze product for a swift and effective solution for sucking pests. Pesto Raze spray rapidly controls whitefly problems.\\nQ3 What is the recommended insecticide for aphids and jassids infesting plants?\\nAns. Aphids and jassids pose significant threats to various crops. Opt for Pesto Raze for the rapid control of aphids and jassids. Pesto Raze not only eliminates insects but also addresses all stages of their life cycle.\\nQ4 Which insecticide excels in managing sucking insects in plants?\\nAns. For superior control of sucking insects, Kay Bee Bio’s Pesto Raze bio insecticide delivers outstanding results. It swiftly manages pests like whiteflies, aphids, and jassids in plants.\\nQ5 In which crops can Pesto Raze insecticide be used?\\nAns. Pesto Raze is suitable for application in a wide range of crops, including tomatoes, chilli, capsicum, brinjal, okra, potato, onion, pomegranate, guava, ginger, soybean, as well as all oilseeds, pulses, vegetables, and fruit crops. It is a high-performance organic insecticide product for vegetables.\\nDurga Ramaji –\\nHelps keeping sucking pests away and because it is organic it is super safe and pet friendly\\nSachin Salunkhe –\\nपांढरी माशी. साठी स्प्रे घेतला. झटक्यात रिझल्ट.\\nNamarat Waychal –\\nपांढरी माशी पंधरा मिनिटात खतम\\nAmit Gaikwd –\\nपांढरी माशी. साठी स्प्रे घेतला. झटक्यात रिझल्ट.\\nNice product'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------\n",
        "# 🔍 Step 5: Retrieve top documents from BOTH collections\n",
        "# ---------------------------------------------------------------\n",
        "query_embedding = embedder.encode(query).tolist()\n",
        "\n",
        "# Get top 2 web scraped contexts\n",
        "web_results = web_collection.query(query_embeddings=[query_embedding], n_results=2)\n",
        "web_contexts = web_results[\"documents\"][0] if web_results[\"documents\"] else []\n",
        "\n",
        "# Get top 2 QA reference answers\n",
        "qa_results = qa_collection.query(query_embeddings=[query_embedding], n_results=2)\n",
        "qa_contexts = qa_results[\"documents\"][0] if qa_results[\"documents\"] else []\n",
        "\n",
        "# Combine all context\n",
        "combined_context = \"\\n\".join(qa_contexts + web_contexts)\n",
        "\n",
        "if not combined_context.strip():\n",
        "    raise Exception(\"❌ No context found from either source.\")\n",
        "\n",
        "print(\"\\n--- Combined Retrieved Context ---\\n\", combined_context[:1000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqLBYt9sQ1lh",
        "outputId": "cf5264ab-910b-461b-ff5c-1ef08e0d9635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Combined Retrieved Context ---\n",
            " suggested to apply amister @ 2 ml per litre of water.\n",
            "spray malathion 50 ec @ 2 ml per liter of water\n",
            "Broccoli aphids - Ask Extension\n",
            "My broccoli became infested with aphids. I have been pulling the plants and disposing of them in the trash (not composting). Do I need to treat my g...\n",
            "Knowledgebase\n",
            "Broccoli aphids #853297\n",
            "Asked October 17, 2023, 12:46 AM EDT\n",
            "My broccoli became infested with aphids. I have been pulling the plants and disposing of them in the trash (not composting). Do I need to treat my garden beds now to keep them from next year’s garden? Is there an organic solution?\n",
            "Benton County Oregon\n",
            "Expert Response\n",
            "Thanks for contacting \"Ask Extension\" about your aphid problem. You do not need to treat your garden beds.\n",
            "Removing the broccoli and tossing the broccoli was the right move! Next you need to remove nearby weeds where aphids tend to overwinter (especially weeds related to the mustard family).\n",
            "To control aphids in your garden:\n",
            "- Keep a watch on the aphid population next \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# 🤖 Step 6: Generate answer using Groq LLaMA\n",
        "# ---------------------------------------------\n",
        "client = Groq(api_key=\"Your_Groq_API_Key\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an agricultural expert. Use only the context to answer the question. Be specific and practical. Do not make things up.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Context:\\n{combined_context}\\n\\nQuestion: {query}\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "generated_answer = response.choices[0].message.content\n",
        "print(\"\\n--- Generated Answer ---\\n\", generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny9AZY93Q5oJ",
        "outputId": "e6ee55f3-8cb7-4b5e-ea90-c0de838632cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generated Answer ---\n",
            " For controlling aphids in brinjal, you have a couple of options:\n",
            "\n",
            "1. **Amistar**: Apply Amistar at 2 ml per liter of water.\n",
            "2. **Malathion 50 EC**: Spray Malathion 50 EC at 2 ml per liter of water.\n",
            "3. **Pesto Raze**: This is an organic insecticide, and the recommended dosage for brinjal is 1.5-2.5 ml/liter of water.\n",
            "\n",
            "It's always a good idea to check the product label and follow the instructions carefully. Also, consider integrated pest management strategies like introducing beneficial insects, removing weeds, and using physical barriers to control aphid populations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from groq import Groq\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import trafilatura\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 🔧 Setup\n",
        "# ---------------------------------------------\n",
        "client = Groq(api_key=\"Your_Groq_API_Key\")  # Replace this\n",
        "# ---------------------------------------------\n",
        "# 📥 Load QA Reference Dataset into ChromaDB\n",
        "# ---------------------------------------------\n",
        "df = pd.read_csv(\"/content/questionsv4.csv\").dropna(subset=[\"questions\", \"answers\"])\n",
        "# ---------------------------------------------\n",
        "# 📥 Load Query Dataset (limit to 10 rows)\n",
        "# ---------------------------------------------\n",
        "df = df.head(10)\n",
        "results = []\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 🔁 Loop and generate answers\n",
        "# ---------------------------------------------\n",
        "def fetch_and_extract(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=60, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        if response.status_code == 200:\n",
        "            return trafilatura.extract(response.text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    query = row[\"questions\"]\n",
        "    reference = row[\"answers\"]\n",
        "    print(f\"\\n🔁 Processing Query {idx+1}: {query}\")\n",
        "\n",
        "    try:\n",
        "        # 🌐 Step 1: Get URLs from n8n\n",
        "        n8n_webhook_url = \"https://rrajdev.app.n8n.cloud/webhook/farm-query\"\n",
        "        response = requests.post(n8n_webhook_url, json={\"query\": query})\n",
        "        urls = response.json().get(\"urls\", [])\n",
        "        if not urls:\n",
        "            print(\"❌ No URLs found.\")\n",
        "            continue\n",
        "\n",
        "        # 🧹 Step 2: Scrape content\n",
        "        cleaned = []\n",
        "        for url in urls:\n",
        "            content = fetch_and_extract(url)\n",
        "            if content:\n",
        "                cleaned.append({\"url\": url, \"content\": content})\n",
        "\n",
        "        if not cleaned:\n",
        "            print(\"❌ No content scraped.\")\n",
        "            continue\n",
        "\n",
        "        # 🧠 Step 3: Store cleaned web context in Chroma\n",
        "        for i, entry in enumerate(cleaned):\n",
        "            embedding = embedder.encode(entry[\"content\"]).tolist()\n",
        "            web_collection.add(\n",
        "                ids=[f\"web_{idx}_{i}\"],\n",
        "                documents=[entry[\"content\"]],\n",
        "                embeddings=[embedding],\n",
        "                metadatas=[{\"source\": entry[\"url\"]}]\n",
        "            )\n",
        "\n",
        "        # 🔍 Step 4: Retrieve context from BOTH sources\n",
        "        query_embedding = embedder.encode(query).tolist()\n",
        "\n",
        "        web_results = web_collection.query(query_embeddings=[query_embedding], n_results=2)\n",
        "        web_contexts = web_results[\"documents\"][0] if web_results[\"documents\"] else []\n",
        "\n",
        "        qa_results = qa_collection.query(query_embeddings=[query_embedding], n_results=2)\n",
        "        qa_contexts = qa_results[\"documents\"][0] if qa_results[\"documents\"] else []\n",
        "\n",
        "        combined_context = \"\\n\".join(qa_contexts + web_contexts)\n",
        "        safe_context = combined_context[:3000]\n",
        "\n",
        "        if not combined_context.strip():\n",
        "            print(\"❌ No relevant context found.\")\n",
        "            continue\n",
        "\n",
        "        # 🤖 Step 5: Ask Groq LLM\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an agricultural extension officer. Based strictly on the context provided, give a specific, actionable answer. Include names of pesticides, dosage, agency names, schemes, or institutions if available in the context. Do not guess or make up answers not found in the context.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Context:\\n{safe_context}\\n\\nQuestion: {query}\"\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "\n",
        "        # ✅ Step 6: Store results\n",
        "        results.append({\n",
        "            \"query\": query,\n",
        "            \"answer\": answer,\n",
        "            \"reference\": reference\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing query {idx+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 💾 Save final results to CSV\n",
        "# ---------------------------------------------\n",
        "output_df = pd.DataFrame(results)\n",
        "output_df.to_csv(\"groq_farming_with_ref_combined.csv\", index=False)\n",
        "print(\"\\n✅ Completed! Saved to 'groq_farming_with_ref_combined.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-daxE3z5wuUY",
        "outputId": "08dda64f-1c83-48f7-9163-fad0ee48910d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 1: asking about the control measure for aphid infestation in mustard crops\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Error processing query 1: no healthy upstream\n",
            "\n",
            "🔁 Processing Query 2: asking about the control measure of flower drop problem in his coconut plant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Error processing query 2: no healthy upstream\n",
            "\n",
            "🔁 Processing Query 3: asking about how to avail kisan credit card loan for sali crop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching https://agri.odisha.gov.in/sites/default/files/2024-07/Implementation%20of%20Pradhan%20Mantri%20Fasal%20Bima%20Yojana%20%28PMFBY%29%20during%20Kharif%202024_0.pdf: HTTPSConnectionPool(host='agri.odisha.gov.in', port=443): Read timed out. (read timeout=60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
            "ERROR:trafilatura.core:empty HTML tree: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 4: asking about source of early ahu rice variety\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 5: asking that he has not got proper friut from his coconut plant\n",
            "\n",
            "🔁 Processing Query 6: asking about induced breeding of fishes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 7: asking about training for preparation of biomanure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
            "ERROR:trafilatura.core:empty HTML tree: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 8: asking about treatment of low production of milk in cow\n",
            "\n",
            "🔁 Processing Query 9: asking about the premature fruit dropping of coconut.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Processing Query 10: asking  about  preservatives  of  tomato squash.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Completed! Saved to 'groq_farming_with_ref_combined.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas requests --quiet"
      ],
      "metadata": {
        "id": "sXU2nmjF0JIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# 🔑 Set your Groq API Key here\n",
        "GROQ_API_KEY = \"Your_Groq_API_Key\"  # Replace with your Groq API key"
      ],
      "metadata": {
        "id": "dWz4GSaK0aQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 Evaluation function using Groq's LLaMA 3\n",
        "def auto_evaluate_with_groq(query, answer, reference):\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a neutral and strict evaluator.\n",
        "\n",
        "Your task is to compare the chatbot's answer to a trusted reference answer for a farming question.\n",
        "\n",
        "### Scoring Rubric (1 to 5):\n",
        "- 5 = The chatbot’s answer is fully accurate, equivalent to the reference answer in meaning and usefulness.\n",
        "- 4 = The answer is mostly accurate and close to the reference but misses 1 minor point or detail.\n",
        "- 3 = The answer captures the general idea but is incomplete, vague, or less specific than the reference.\n",
        "- 2 = The answer is mostly incorrect or significantly less informative than the reference.\n",
        "- 1 = The answer is wrong, irrelevant, or contradicts the reference.\n",
        "\n",
        "### Instructions:\n",
        "- Evaluate the chatbot's answer **only in comparison to the reference answer**.\n",
        "- Focus on correctness, completeness, and whether the user would get equally useful help from both.\n",
        "- Be objective and avoid inflated scores.\n",
        "- Then provide a brief 1-line comment justifying your scores.\n",
        "\n",
        "### Output Format:\n",
        "Return your evaluation in this exact JSON format:\n",
        "{{\n",
        "  \"match\": <1–5>,\n",
        "  \"helpfulness\": <1–5>,\n",
        "  \"trustworthiness\": <1–5>,\n",
        "  \"comments\": \"<Your one-line comment here>\"\n",
        "}}\n",
        "\n",
        "---\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Chatbot Answer:\n",
        "{answer}\n",
        "\n",
        "Reference Answer:\n",
        "{reference}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"llama3-70b-8192\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    return response.json()['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "f7TFv1OA0dfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📥 Load dataset from CSV\n",
        "df = pd.read_csv(\"/content/groq_farming_with_ref_combined.csv\")\n",
        "\n",
        "# 🔁 Evaluate each row and collect results\n",
        "results = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    print(f\"Evaluating Query {idx+1}: {row['query']}\")\n",
        "\n",
        "    try:\n",
        "        review = auto_evaluate_with_groq(row[\"query\"], row[\"answer\"], row[\"reference\"])\n",
        "    except Exception as e:\n",
        "        review = f\"Error during evaluation: {e}\"\n",
        "\n",
        "    results.append({\n",
        "        \"query\": row[\"query\"],\n",
        "        \"answer\": row[\"answer\"],\n",
        "        \"reference\": row[\"reference\"],\n",
        "        \"evaluation\": review\n",
        "    })\n",
        "\n",
        "# 💾 Save evaluation results\n",
        "eval_df = pd.DataFrame(results)\n",
        "eval_df.to_csv(\"groq_evaluated_output_ref2.csv\", index=False)\n",
        "\n",
        "print(\"✅ Evaluation complete. Results saved to 'groq_evaluated_output_ref.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPVINFzh0jCw",
        "outputId": "92024c87-d5b7-4b6a-80e0-c6214add9ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Query 1: asking about how to avail kisan credit card loan for sali crop.\n",
            "Evaluating Query 2: asking about source of early ahu rice variety\n",
            "Evaluating Query 3: asking that he has not got proper friut from his coconut plant\n",
            "Evaluating Query 4: asking about induced breeding of fishes\n",
            "Evaluating Query 5: asking about training for preparation of biomanure\n",
            "Evaluating Query 6: asking about treatment of low production of milk in cow\n",
            "Evaluating Query 7: asking about the premature fruit dropping of coconut.\n",
            "Evaluating Query 8: asking  about  preservatives  of  tomato squash.\n",
            "✅ Evaluation complete. Results saved to 'groq_evaluated_output_ref.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMvu9H0n1Qye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}